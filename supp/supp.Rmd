---
title: "Supplemental Materials for: A robust and readily implementable method for the meta-analysis of response ratios with and without missing standard deviations"
author: Shinichi Nakagawa, Daniel W. A. Noble, Malgorzata Lagisz, Rebecca Spake, Wolfgang Viechtbauer and Alistair M. Senior 
date: "`r Sys.Date()`"
bibliography: ./bib.bib
csl: ./ecology-letters.csl
output: 
  bookdown::html_document2:
    code_folding: hide
    number_sections: no
    toc: yes
    toc_depth: 6
    toc_float: yes
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = FALSE)
options(digits=2)
```

```{r klippy, echo=FALSE, include=TRUE, message=FALSE, warning=FALSE}
#install.packages("devtools")
remotes::install_github("rlesur/klippy")
klippy::klippy(tooltip_message = 'Click to Copy Code', tooltip_success = 'Done', position = 'right', color = "red")
```

# **Citation**
Please cite the following paper for the methods proposed for dealing with missing standard deviations: 

Shinichi Nakagawa, Daniel W. A. Noble, Malgorzata Lagisz, Rebecca Spake, Wolfgang Viechtbauer and Alistair M. Senior. 2022. A robust and readily implementable method for the meta-analysis of response ratios with and without missing standard deviations. 

# **General Introduction**

In this supplement we show readers how they can implement some of the missing data approaches covered within our paper to deal with missing standard deviations when using log response ratios (*lnRR*). We provide code snippets that can be copied and added to the users consol. We make use of our worked example from the main manuscript to demonstrate how to apply the methods. We then turn to a second worked example where the authors applied similar methods to deal with missing standard deviations.

Importantly, this tutorial is self-contained. The code will download all the necessary files needed to run the examples directly to your working directory. This includes a subset of data from @bird2019, along with their pruned phylogenetic tree, and data from @mcdonald2019. For simplicity, we have not provided the code here to show readers how to prune the tree and process the data. That code can all be found on our [GitHub](https://github.com/AlistairMcNairSenior/Miss_SD_Sim) repository. Similarly, if users experience any issues with downloading the files needed to run any code they are hosted on [OSF](https://osf.io/h9x6w/). 

# Extending the proposed methods to more complex situations 

JUST PUTTING IT HERE - talk to Dan

In many ecological meta-analyses, meta-analytic models are often made more complex by the need to account for phylogenetic relatedness when a meta-analytic dataset contains multiple species. Moreover, almost all meta-analytic studies test a number of moderators (predictors) to explain heterogeneity among effect sizes (i.e., meta-regression). Furthermore, effect sizes from the same studies can be correlated at the level of sampling error (e.g., the same individuals are used to calculate 2 effect sizes, see Noble et al. (2017). We can write a meta-analytic model which can accommodate these three points above, as follows (Nakagawa & Santos 2012; Cinar et al. 2022):

## Equation 14

where x_k is the kth moderator’s value and β_k is the regression coefficient of the kth moderator (h = 1, 2, …, Nmod, the number of moderators), ah is the phylogenetic effect for the hth species, considered multivariate normally distributed with a covariance of σ_a^2 "A"  (A is a correlation matrix derived from a phylogeny; see Hadfield & Nakagawa 2010); qh is the non-phylogenetic effect for the hth species, distributed with the variance of σ_q^2 (h = 1, 2, …, Nspecies, the number of species, which is different from Nstudy > Neffect-size); and the other notations are the same as above. M* is a variance-covariance matrix of the sampling variance, which may result, say, when effect sizes share a common-control (e.g., Noble et al. 2017); for example, when we have 5 cases from 3 studies, M* can be written as:

## Equation 15

where v_1 and v_2 are the sampling variances for the 1st and 2nd effect sizes from the same study, and ρ√(v_1 v_2 ) and ρ√(v_2 v_1 ) are the co-variances between the two effect sizes (the 1st study), v_3, v_4 and come from the same study (the 2nd study; if we want to make this equation similar to Equation 12, then v_3=ϕv ̃_3 and v_4=ϕv ̃_4), and v_5 is the sampling variance of the 5th effect size from another study. The correlation ρ needs to be provided, but can often be assumed to be 0.5 or 0.8 (Noble et al. 2017; for a formula for the direct estimation of the sampling covariance for lnRR, see Lajeunesse 2011).

Constructing M* may be as challenging as just doing MI for many ecologists, because the actual value of ρ is often unknown (Noble et al. 2017). Fortunately, Hedges et al. (2010) derived the robust variance estimator (RVE), which bypasses these challenges by estimating ρ from the data. By using RVE we need only construct M, rather than M* (see also Tipton 2013). We show an implementation of this procedure in Supporting Information, using the clubSandwitch package (Pustejovsky 2017), which implements the RVE method with a multilevel meta-analysis in metafor (cf. Pustejovsky & Tipton 2021). 


# **`cv_avg` Function**: Calculating between study $CV^2$
To facilitate application of the methods we have written a general function for calculating the weighted $CV^2$ across studies. That function is in the `func.R` script, but we provide some detail here. 

```{r echo = TRUE, results='hide', tidy=FALSE, tidy.opts=list(width.cutoff=80), class.source='klippy'}
#' @title cv_avg
#' @description Calculates the weighted average CV^2 within a study and the weighted average CV^2 across a study
#' @param x Mean of an experimental group
#' @param sd Standard deviation of an experimental group
#' @param n The sample size of an experimental group
#' @param group Study, grouping or cluster variable one wishes to calculate the within and between weighted CV^2. In meta-analysis this will most likely be 'study'.
#' @param data The dataframe containing the mean, sd, n and grouping variables
#' @param label A character string specifying the label one wishes to attach to columns to identify the treatment. Otherwise, if not specified it will default to the variable name for x
#' @param sub_b A logical indicating whether the between study CV^2 (b_CV2) should be appended to the data only ('TRUE') or whether both within study CV^2 (w_CV2), mean sample size (n_mean) and between study CV^2 (b_CV2) should all be appended to the data only ('FALSE')

cv_avg <- function(x, sd, n, group, data, label = NULL, sub_b = TRUE){

  # Check if the name is specified or not. If not, then assign it the name of the mean, x, variable input in the function. https://stackoverflow.com/questions/60644445/converting-tidyeval-arguments-to-string
  if(is.null(label)){
    label <- purrr::map_chr(enquos(x), rlang::as_label)
  }

  # Calculate between study CV. Take weighted mean CV within study, and then take a weighted mean across studies of the within study CV. Weighted based on sample size and pooled sample size.
  b_grp_cv_data <- data                                             %>%
    dplyr::group_by({{group}})                            %>%
    dplyr::mutate(w_CV2 = weighted.mean(na_if(({{sd}} / {{x}})^2, Inf), 
                                        {{n}},na.rm = TRUE),
                  n_mean = mean({{n}}, na.rm = TRUE))   %>%
    dplyr::ungroup(.)                                     %>%
    dplyr::mutate(b_CV2 = weighted.mean(w_CV2, n_mean, na.rm = TRUE), .keep = "used")

  # Make sure that label of the calculated columns is distinct from any other columns
  names(b_grp_cv_data) <- paste0(names(b_grp_cv_data), "_", label)

  # Append these calculated columns back to the original data and return the full dataset.
  if(sub_b){
    b_grp_cv_data <- b_grp_cv_data %>% dplyr::select(grep("b_", names(b_grp_cv_data)))
    dat_new <- cbind(data, b_grp_cv_data)
  } else {
    dat_new <- cbind(data, b_grp_cv_data)
  }

  return(data.frame(dat_new))
}

```

The function will take the mean (`x`), standard deviation (`sd`) and sample size (`n`) along with the desired dataframe and calculate the between study $CV^2$ that is needed for many of the methods implemented. The `group` argument is needed to identify the "study" / cluster variable which is important so that the function first takes the weighted mean $CV^2$ within the study before calculating the $CV^2$ across studies. The new $CV^2$ is then added directly to the dataframe. You can label these new columns using the `label` argument, otherwise, it will append the name of the column for the treatment group with `b_CV2`. We'll show how this function is used as we overview the methods in detail below.

# **Worked Example 1**: Dealing with missing SD data to explore the fitness impacts of competition between herbivorous insects

### Introduction
@bird2019 conducted a meta-analysis exploring the impacts of competition on herbivorous insect fitness when occupying the same host plant with another species or in isolation. Building on work by  @Kaplan2007, they collected data on a series of fitness measurements [e.g., abundance, body size, development time, fecundity; see Table 1 in @bird2019] and explored the overall impacts of competition on the various fitness measures independently and in composite analyses. @bird2019 also tested the importance of a series of moderators they predicted would impact the magnitude of competition between species including population density, phylogenetic distance, diet breadth and spatial and temporal separation. A phylogeny was constructed using DNA sequence data and this gene tree was used to control for phylogenetic non-independence within analyses. 

For demonstration purposes, we focus on a subset of fitness data, abundance, and use a simple multilevel meta-analytic model to estimate the overall impact of competition on focal insect fitness (i.e., intercept or overall meta-analytic mean) while controlling for phylogeny, research group, and research year [as per the analysis by @bird2019]. Our use of log response ratio (lnRR) meant that we could only use a subset of abundance data from @bird2019 because of lnRR requiring ratio scale data. In addition, the ratio of minimum to largest sampling error variance calculated from the raw data was high suggesting some errors in the original published papers.  To avoid model convergence issues we excluded these data and used a sample comprised of 293 effect sizes across 67 unique focal insect species with known phylogenetic relationships. We then introduced missing data at the paper level so that ~20% of papers had effect sizes with missing SD in the control and experimental treatment; a scenario that is typical of many meta-analyses. 

### Setting up

First, load the libraries and source functions:

```{r echo = TRUE, eval = TRUE, class.source='klippy', results='hide'}
#install.packages("pacman")
pacman::p_load(tidyverse, metafor, here, osfr, ape, phytools)

# Useful functions for calculating CV^2 within and between studies
osfr::osf_retrieve_file("https://osf.io/sqr4w/") %>% osfr::osf_download(conflicts = "overwrite")
source(here::here("func.R"))
```

Then, download the data file and phylogenetic tree file that we will use to demonstrate the examples

```{r echo = TRUE, eval = TRUE, results='hide', class.source='klippy'}
# Download the data file from OSF
osfr::osf_retrieve_file("https://osf.io/evysw/") %>% osfr::osf_download(conflicts = "overwrite") 

# Download the phylogeny from OSF
osfr::osf_retrieve_file("https://osf.io/t5kh4/") %>% osfr::osf_download(conflicts = "overwrite") 

# Load the data file and tree file
 data1 <- read.csv(here::here("example1.csv"))
  tree <- read.tree(here::here("phylo_tree"))
 phylo <- vcv(tree, corr = TRUE)
```

The data from @bird2019 is incomplete. It is missing many SD values in the control and treatment group, which would normally mean we would have to exclude these data prior to analysis (Figure \@ref(fig:fig1))

```{r fig1, fig.cap = "Missing data in the Bird et al. (2019) dataset", echo=FALSE, eval = TRUE, include=TRUE, message=FALSE, warning=FALSE}
na.plot <- data1 %>%
  mutate(id = row_number()) %>%
  gather(-id, key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  ggplot(aes(key, id, fill = isna)) +
    geom_raster(alpha=0.8) +
    scale_fill_manual(name = "",
        values = c('steelblue', 'tomato3'),
        labels = c("Present", "Missing")) +
    labs(x = "Variable",
           y = "Row Number") +
    coord_flip()

na.plot
```

### Method 1A  

In our manuscript we provide the full data and complete case analysis (excluding rows with missing data). As such, here we jump straight into showing readers how to implement the different solutions to the missing standard deviation problem that is typical when conducting meta-analysis.

To implement Method 1 described in the manuscript, we need to first calculate the between study $CV^2$. We will do this with the `cvg_avg` function we describe above. Here, we need to do this for the control and experimental groups as follows, such that variable `b_CV_1` and `b_CV_2` are the averages for the control and experimental groups, respectively:

```{r cvavg, echo=TRUE, include=TRUE, message=FALSE, warning=FALSE, class.source='klippy'}
# Calculate the average between study CV, which will replace missing values.
    data1 <- cv_avg(x = Control_mean, sd = Control_standard_deviation,
                            n = Control_sample_size, group = Author, label = "1",
                             data = data1)
    data1 <- cv_avg(x = Experimental_mean, sd = Experimental_standard_deviation,
                            n = Experimental_sample_size, group = Author,
                            label = "2", data = data1)
```

To implement Method 1A, we need to calculate log response ratios and their associated sampling variances differently depending on whether we have an observation with a missing standard deviation (SD) or not. Accoring to Table 1 (in the main MS), we can use equation 4 or 6 for the point estimate calculation and equation 5 for the sampling variance when we have a known SD and equation 7 when we have an unknown SD. We can do that as follows:

```{r lnRR_1A, echo=TRUE, include=TRUE, message=FALSE, warning=FALSE, class.source='klippy'}
    # Use weighted mean CV in replacement for where CV's are missing. Otherwise, calculate CV^2 of data that is known.
    data1 <- data1 %>%
              mutate(cv2_cont_new = if_else(is.na(cv_Control),      b_CV2_1, cv_Control^2),
                     cv2_expt_new = if_else(is.na(cv_Experimental), b_CV2_2, cv_Experimental^2))

    # Now calculate new yi and vi, called lnrr_laj & v_lnrr_laj, respectively. This uses either the between individual CV^2 when missing or normal CV^2 when not missing.
    data1 <- data1 %>%
              mutate(lnrr_laj = lnrr_laj(m1 = Control_mean, m2 = Experimental_mean,
                                         cv1_2 = cv2_cont_new, cv2_2 = cv2_expt_new,
                                         n1= Control_sample_size, n2 = Experimental_sample_size),
                   v_lnrr_laj = v_lnrr_laj(cv1_2 = cv2_cont_new, n1= Control_sample_size,
                                           cv2_2 = cv2_expt_new, n2 = Experimental_sample_size))
```

Now we are ready to fit our multilevel meta-analytic model as per @bird2019.

```{r bird_1A, echo=TRUE, include=TRUE, message=FALSE, warning=FALSE, class.source='klippy'}

########## METHOD 1A ##########


    # Fit model with new sampling variance
    method_1A_bird <- rma.mv(lnrr_laj ~ 1, V = v_lnrr_laj,
                               random=list(~1|Group, ~1|Year, ~1|Focal_insect, ~1|obs),
                               R = list(Focal_insect = phylo), data = data1)

    method_1A_bird_res <- get_est(method_1A_bird)
```    
    

### Method 1B
While Method 1A could be used our simulations show that it is better to apply Method 1B. The only real difference is that we apply eqation 7 to calculate sampling variance regardless of whether we are missing the standard deviation or not for a row. In otherwords, we simply using the between study $CV^2$ for all CV's in the control and experimental group. 

```{r lnRR_1B, echo=TRUE, include=TRUE, message=FALSE, warning=FALSE, class.source='klippy'}

    # Now calculate new v_lnrr_laj_1B using between study CV^2 for all observations.
    data1 <- data1 %>%
              mutate(v_lnrr_laj_1B = v_lnrr_laj(cv1 = b_CV2_1, n1= Control_sample_size,
                                                cv2 = b_CV2_2, n2 = Experimental_sample_size))
```

Now we can fit the same model as described above using this new sampling variance:

```{r bird_1B, echo=TRUE, include=TRUE, message=FALSE, warning=FALSE, class.source='klippy'}

     ########## METHOD 1B  ##########

    # Fit model with new sampling variance and point estimate
    method_1B_bird <- rma.mv(lnrr_laj ~ 1, V = v_lnrr_laj_1B,
                           random=list(~1|Group, ~1|Year, ~1|Focal_insect, ~1|obs),
                           R = list(Focal_insect = phylo), data = data1)

    method_1B_bird_res <- get_est(method_1B_bird)
```

### Method 2
Method 2 involves a weighted regression approach. This can be implemented as follows:

```{r bird_2, echo=TRUE, include=TRUE, message=FALSE, warning=FALSE, class.source='klippy'}

     ########## METHOD 2  ##########

                 V_es <- diag(data1$v_lnrr_laj_1B)
      row.names(V_es) <- data1$obs
           data1$obs2 <- rownames(V_es)

    method2_bird <-rma.mv(lnrr_laj ~ 1, V = 0, 
                          random=list(~1|Group, ~1|Year,
                                      ~1|Focal_insect, ~1|obs, ~1|obs2),
                        data=data1, R=list(obs2=V_es, Focal_insect = phylo),
                        Rscale=F)
    
    method2_bird_res <- get_est(method2_bird)
```

### Method 3
Method 3 is a combined approach using Equation 5 as the sampling variance when we have the full data; otherwise using a weighted regression approach.

```{r bird_3, echo=TRUE, include=TRUE, message=FALSE, warning=FALSE, class.source='klippy'}

 ########## METHOD 3  ##########

    # Find where missing SD's are in the data
      missing_dat <- which(is.na(data1$Control_standard_deviation) & is.na(data1$Experimental_standard_deviation))

    # Set the effect sizes not missing data to zero in the V_es matrix
                        V_es2 <- diag(data1$v_lnrr_laj_1B)
    diag(V_es2)[-missing_dat] <- 0
             row.names(V_es2) <- data1$obs
                   data1$obs2 <- rownames(V_es2)

    # Set the v_lnrr_laj to 0
                 data1$v_lnrr_laj_m3 <- data1$v_lnrr_laj
    data1$v_lnrr_laj_m3[missing_dat] <- 0

    method3_bird <-rma.mv(lnrr_laj ~ 1, V = v_lnrr_laj_m3, 
                          random = list(~1|Group, ~1|Year, ~1|Focal_insect, ~1|obs, ~1|obs2),
                            data = data1, R = list(obs2=V_es2, Focal_insect = phylo), Rscale=F)
    method3_bird_res <- get_est(method3_bird)
```

### Comparing results
We can compare the results of all the methods together (Table \@ref(tab:birdResults)):

```{r birdResults, tab.cap = "Results from re-analysis of Bird et al. 2019", echo=FALSE, include=TRUE, message=FALSE, warning=FALSE, class.source='klippy'}
 results <- rbind(method_1A_bird_res, method_1B_bird_res, method2_bird_res, method3_bird_res)
    results$Method <- c("Method 1A", "Method 1B", "Method 2", "Method 3")
    
    results <- results %>% select(Method, Est., SE, "95% LCI", "95% UCI")
    flextable::flextable(results) %>% flextable::width(j = c(1, 5), c(0.9, 0.8))
```
# **Worked Example 2**: Dealing with missing SD data when assessing strategic-rest grazing (SRG) regimes on both ungrazed and constantly grazed (CG) systems

### Introduction
Our second example is from @mcdonald2019 which demonstrates nicely a real dataset with  missing standard deviation data as a result of it not being reported within papers. @mcdonald2019 studied the effects of strategic-rest grazing (SRG) regimes on both ungrazed and constantly grazed (CG) systems. They looked at a number of different ecological outcomes. Here, we focus on the effects of SRG vs CG on biomass; this dataset contains 173 effect sizes from 67 studies. In their original analysis @mcdonald2019 find that the biomass of CG systems is significantly reduced relative to that SRG, but do not report the total heterogeneity. The dataset contains two dimensions of non-independence that are common to eco-evolutionary meta-analyses; 1) multiple effect sizes per study and 2) several effect sizes within the same study are computed as relative to the same control group [sometimes termed ‘stochastic dependency’; @Noble2017; @GleserOlkin2009]. For now, we will ignore point 2 for ease of presentation.

### Setting up

```{r echo = TRUE, eval = TRUE, results='hide', class.source='klippy'}
#install.packages("pacman")
pacman::p_load(tidyverse, metafor, here, osfr, ape, phytools)

# Useful functions for calculating CV^2 within and between studies
osfr::osf_retrieve_file("https://osf.io/sqr4w/") %>% osfr::osf_download(conflicts = "overwrite")
source(here::here("func.R"))

# Download the data file from OSF
osfr::osf_retrieve_file("https://osf.io/at6pn/") %>% osfr::osf_download(conflicts = "overwrite") 

# Load the data file and tree file
data2 <- read.csv(here::here("example2.csv"))
data2$ES_ID<-as.factor(seq(1, nrow(data2), 1))
```

Of the `r dim(data2)[1]` effect sizes in the biomass dataset, `r (sum(is.na(data2$CSD)) / dim(data2)[1])*100`% have missing SD data (Figure \@ref(fig:fig2)). Where missing, SDs were missing for both the CG (`CSD` in data) and SRG (`TSD` in data) treatment groups in the effect size (Figure \@ref(fig:fig2)). In their original analyses @mcdonald2019 handle these missing data by calculating the average CV from all studies without missing data. They then use the reported mean value for studies with missing SDs coupled with the average CV to impute the missing SD value. This method is similar to single imputation of missing SDs, by predicting their value from a mean-SD linear regression. Non-independence was handled by @mcdonald2019 using MLMA, which included a variance-covariance matrix to account for stochastic dependency.

```{r fig2, fig.cap = "Missing data in the McDonald et al. (2019) dataset.", echo=FALSE, eval = TRUE, include=TRUE, message=FALSE, warning=FALSE}
na.plot2 <- data2 %>%
  mutate(id = row_number()) %>%
  gather(-id, key = "key", value = "val") %>%
  mutate(isna = is.na(val)) %>%
  ggplot(aes(key, id, fill = isna)) +
    geom_raster(alpha=0.8) +
    scale_fill_manual(name = "",
        values = c('steelblue', 'tomato3'),
        labels = c("Present", "Missing")) +
    labs(x = "Variable",
           y = "Row Number") +
    coord_flip()

na.plot2
```

### Method 1A

Again, we need to calculate log response ratios and their associated sampling variances differently depending on whether we have an observation with a missing standard deviation (SD) or not. First, we need to calculate $CV^2$, which will make it easy to set up the data.

```{r cvavg2, echo=TRUE, include=TRUE, message=FALSE, warning=FALSE, class.source='klippy'}
# Calcuclate CV  
      data2 <- data2 %>% 
                mutate(     cv_Control = na_if(CSD / CM, Inf),
                       cv_Experimental = na_if(TSD / TM, Inf))

# Calculate the average between study CV, which will replace missing values.
    data2 <- cv_avg(x = CM, sd = CSD,
                            n = CN, group = Study, label = "1",
                             data = data2)
    data2 <- cv_avg(x = TM, sd = TSD,
                            n = TN, group = Study,
                            label = "2", data = data2)
    
     # Use weighted mean CV in replacement for where CV's are missing. Otherwise, calculate CV^2 of data that is known.
    data2 <- data2 %>%
              mutate(cv2_cont_new = if_else(is.na(cv_Control),      b_CV2_1, cv_Control^2),
                     cv2_expt_new = if_else(is.na(cv_Experimental), b_CV2_2, cv_Experimental^2))

```

Accoring to Table 1 (in the main MS), we can use equation 4 or 6 for the point estimate calculation and equation 5 for the sampling variance when we have a known SD and equation 7 when we have an unknown SD. We can do that as follows:

```{r lnRR_McDon1A, echo=TRUE, include=TRUE, message=FALSE, warning=FALSE, results='hide', class.source='klippy'}
   
    # Now calculate new yi and vi, called lnrr_laj & v_lnrr_laj, respectively. This uses either the between individual CV^2 when missing or normal CV^2 when not missing.
    data2 <- data2 %>%
              mutate(lnrr_laj = lnrr_laj(m1 = TM, m2 = CM,
                                         cv1_2 = cv2_expt_new, cv2_2 = cv2_cont_new,
                                         n1= TN, n2 = CN),
                   v_lnrr_1A = v_lnrr_laj( cv1_2 = cv2_expt_new, n1= TN,
                                           cv2_2 = cv2_cont_new, n2 = CN))
```

```{r mcdon_1A, echo = TRUE, eval = TRUE, class.source='klippy'}
# Model 1A: MLMA of missing SD effect sizes using pooled CV2
MLMA1A<-rma.mv(yi = lnrr_laj, V = v_lnrr_1A, random=list(~1|Study, ~1|ES_ID), data=data2)
MLMA1A_res <- get_est(MLMA1A)
```

### Method 1B

We will now calculate a new sampling varinace using Equation 7, that makes use of the weighted between study $CV^2$ for all observed effect sizes.

```{r mcdon_1B, echo = TRUE, eval = TRUE, class.source='klippy'}

 # Now calculate new v_lnrr_laj_1B using between study CV^2 for all observations.
    data2 <- data2 %>%
              mutate(v_lnrr_laj_1B = v_lnrr_laj(cv1_2 = b_CV2_2, n1 = TN,
                                                cv2_2 = b_CV2_1, n2 = CN))

# Model 1B: MLMA of all effect sizes using pooled CV2
MLMA1B<-rma.mv(yi = lnrr_laj, V = v_lnrr_laj_1B, random=list(~1|Study, ~1|ES_ID), data=data2)
MLMA1B_res <- get_est(MLMA1B)
```

### Method 2

Now use the weighted regression approach with Equation 7 as $v_{i}$.
```{r mcdon_2, echo = TRUE, eval = TRUE, class.source='klippy'}
# Model 2: weighted regression of all effect sizes using pooled CV2 
            Vf <- diag(data2$v_lnrr_laj_1B)
 row.names(Vf) <- seq(1, length(data2$v_lnrr_laj_1B), 1)
	colnames(Vf) <- seq(1, length(data2$v_lnrr_laj_1B), 1)
  data2$ES_ID2 <- rownames(Vf)

MLMA2<-rma.mv(yi = lnrr_laj, V = 0, random=list(~1|Study, ~1|ES_ID, ~1|ES_ID2), 
              data=data2, R=list(ES_ID2=Vf), Rscale=F)
MLMA2_res <- get_est(MLMA2)
```


### Method 3

Now use the weighted regression approach with Equation 7 as $v_{i}$, but equation 5 for the sampling variance when SD is known.
```{r mcdon_3, echo = TRUE, eval = TRUE, class.source='klippy'}
# Model 2: weighted regression of all effect sizes using pooled CV2 

missing<-which(is.na(data2$CSD) == T)
diag(Vf)[-missing]<-0

 Vf <- diag(data2$v_lnrr_laj_1B)
 row.names(Vf) <- seq(1, length(data2$v_lnrr_laj_1B), 1)
	colnames(Vf) <- seq(1, length(data2$v_lnrr_laj_1B), 1)
  data2$ES_ID2 <- rownames(Vf)

data2$vi_3<-data2$v_lnrr_1A
data2$vi_3[missing]<-0

MLMA3<-rma.mv(yi = lnrr_laj, V = vi_3, random=list(~1|Study, ~1|ES_ID, ~1|ES_ID2), 
              data=data2, R=list(ES_ID2=Vf), Rscale=F)
MLMA3_res <- get_est(MLMA3)
```

### Comparing results
In Table \@ref(tab:mcDonResults) we present the results of re-analysis of the biomass data from @mcdonald2019, again using MLMA, but with the four different methods to handles missing SDs. For reference we also include the results of a complete cases analysis where studies with missing SDs have been excluded. The effect sizes for the different methods are all very similar, although the CI for the complete cases analysis is wider than for those that include studies with missing SDs. Method 1B estimated slightly lower heterogeneity than the other methods.

```{r mcDonResults, tab.cap = "Results from re-analysis of McDonald et al. 2019", echo=FALSE, include=TRUE, message=FALSE, warning=FALSE, class.source='klippy'}
 results2 <- rbind(MLMA1A_res, MLMA1B_res, MLMA2_res, MLMA3_res)
    results2$Method <- c("Method 1A", "Method 1B", "Method 2", "Method 3")
    
    results2 <- results2 %>% select(Method, Est., SE, "95% LCI", "95% UCI")
    flextable::flextable(results2) %>% flextable::width(j = c(1, 5), c(0.9, 0.8))
```

# **Session Information**
```{r echo = FALSE, eval = TRUE}
sessionInfo() %>% pander::pander()
```

# **References**
